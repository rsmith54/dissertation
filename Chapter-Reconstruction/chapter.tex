%This is the first chapter of the dissertation

%The following command starts your chapter. If you want different titles used in your ToC and at the top of the page throughout the chapter, you can specify those values here. Since Columbia doesn't want extra information in the headers and footers, the "Top of Page Title" value won't actually appear.

\chapter[Event Reconstruction][Top of Page Title]{Event Reconstruction}

This chapter describes the reconstruction algorithms used within ATLAS.\todo{cite fermilab lectures}
We will make the distinction between the ``primitive'' objects which are reconstructed from the detector signals from the ``composite'' physics objects we use in measurements and searches for new physics.

\section{Primitive Object Reconstruction}

The primitive objects reconstructed by ATLAS are \textit{tracks} and (calorimeter) \textit{clusters}.
These are reconstructed directly from tracking hits and calorimeter energy deposits into cells.
Tracks can be further divided into inner detector and muon spectrometer tracks.
Calorimeter clusters can be divided into sliding-window clusters and topological clusters (topoclusters).
% \footnotemark
% \footnotetext{Strictly speaking, sliding-window and topological clustering are the names of the algorithms, and thus one could speak of topological electromagnetic clusters or hadronic sliding-window clusters.
% In ATLAS, sliding-window is almost exclusively used to reconstruct electromagnetic objects and topological clustering is almost exclusively used for hadronic clustering, so to avoid confusion we will use this terminology here.
% These choices are entirely based on optimizing the object reconstruction efficiency relative to the fake rate.
% }
\subsection{Inner Detector Tracks}\label{sec:id_tracks}
\todo{cite paper/note}

Inner detector tracks are reconstructed from hits in the inner detector.
These hits indicate that a charged particle has passed through the detector material.
Due to the 2 T solenoid in the inner detector, the hits associated with any individual particle will be curved; this allows one to measure the momentum of the particle.
In any given event, there is upwards of \todo{number}, making it impossible to do any sort of combinatorics to reconstruct tracks\footnotemark.
There are two algorithms used by ATLAS track reconstruction, known as \textit{inside-out} and \textit{outside-in}.

ATLAS first employs the inside-out algorithm.
First, one assumes the track begins at the interaction point.
Moving out from the interaction point, one creates track seeds.
Track seeds are proto-tracks constructed from three hits; these hits can be distributed as three pixel hits, two pixel hits and one SCT hit, or three SCT hits.
One extrapolates the track and uses a combinatorial Kalman filter \todo{cite}, which adds the rest of the pixel and SCT hits to the seeds.
This is done seed by seed, so it avoids the combinatorial complexity involved with checking all hits with all seeds.
At this point, the algorithm applies an additional filter to avoid ambiguities from nearby tracks.
The TRT hits are then added to the seeds in the same procedure; in this way, all hits are associated to a track.

The next step is to figure out the correct kinematics of the track.
This is done by applying a fitting algorithm which outputs the best-fit track parameters by minimizing the track distance from hits, weighted by each hit's resolution.
These parameters are $(d_0, z_0, \eta, \phi, q/p)$ where $d_0$ ($z_0$) is the transverse (longitudinal) impact parameter and $q/p$ is the charge over the track momenta.
This set of parameters uniquely defines the trajectory of the charged particle associated to the track; an illustration of a track with these parameters is shown in Fig.\ref{fig:track_schematic}.

\begin{figure}
\caption{The parameters associated to a track.}
\label{fig:track_schematic}
\includegraphics[width=.45\linewidth]{track_schematic}
\end{figure}

The other track reconstruction algorithm is the outside-in algorithm.
As the name implies, in this case, we start from the outside of the inner detector, in the TRT, and extend the tracks in.
One begins by seeding from TRT hits, and extending the track back towards the center of the detector.
The same fitting procedure is used as in the inside-out algorithm to find the optimal track parameters.
This algorithm is particularly important for finding tracks which originate from interactions with the detector material, especially the SCT.
For tracks from primary vertices, this often finds the same tracks as the inside-out algorithm, providing an important check on the consistency of the tracking procedure.

In the high lumonosity environment of the LHC, even the tracks reconstructed from precision detectors such as those of ATLAS inner detector can sometimes lead to fake tracks from simple combinatoric chance.
Several quality checks are imposed after track fitting which reduce this background.
Seven silicon (pixel + SCT) hits are required for all tracks.
No more than two holes are allowed in the pixel detector; holes are expected measurements from the track that are missing in the pixel detector.
Finally, tracks with poor fit quality, as measured by $\chi^2/ndf$, are also rejected.
Due to the high quality of the silicon measurements in the pixel detector and SCT, these requirements give good track reconstruction efficiency, as seen in Fig.\ref{fig:track_eff} for simulated events\cite{ATL-COM-PHYS-2012-1541}.
\begin{figure}
\caption{Track reconstruction efficiency as a function of track \pt and $\eta$.
The efficiency is defined as the number of reconstructed tracks divided by the number of generate charged particles.} \label{fig:track_eff}
\subfloat[Track reconstruction as a function of \pt.]   {\includegraphics[width=.45\linewidth]{track_eff_pt}}
\subfloat[Track reconstruction as a function of $\eta$.]{\includegraphics[width=.45\linewidth]{track_eff_eta}} \\
\end{figure}

\subsection{Sliding-window clusters}\label{sec:sliding_window_cluster}

The sliding-window algorithm is a way to combine calorimeter cells into composite objects (clusters) to be used as inputs for other algorithms\cite{PERF-2013-03}.
Sliding-window clusters are the primary inputs to electron and photon reconstruction, as described below.
As described in Ch.\ref{ch:atlas}, the electromagnetic calorimeter has high granularity, with a cell size of $(\eta, \phi) = (.025, .025)$ in the coarsest second layer throughout most of the calorimeter.
The ``window'' consists of 3 by 5 cells in the $(\eta, \phi)$ space; all layers are added on this same 2D space.
One translates this window over the space and seeds a cluster whenever the energy sum of the cells is maximized.
If the seed energy is greater than 2.5 \GeV, this seed is called a sliding-window cluster.
This choice was motivated to optimize the reconstruction efficiency of proto-electrons and proto-photons while rejecting fakes from electronic noise and additional particles from pileup vertices.

\subsection{Topological clusters}\label{sec:topoclusters}

Topoclusters are the output of the algorithm used within ATLAS to combine hadronic and electromagnetic calorimeter cells in a way which extracts signal from a background of significant electronic noise\cite{PERF-2014-07}.
They are the primary input to the algorithms which reconstruct jets.

Topological clusters are reconstructed from calorimeter cells in the following way.
First, one maps all cells onto a single $\eta-\phi$ plane so one can speak of \textit{neighboring} cells.
Two cells are considered neighboring if they are in the same layer and directly adjacent, or if they are in adjacent layers and overlap in $\eta-\phi$ space.
The \textit{significance} $\xi_{\text{cell}}$ of a cell during a given event is

\begin{equation}
\calosig = \frac{E_{\text{cell}}}{\sigma_{\text{noise,cell}}}
\end{equation}

where $\sigma_{\text{noise,cell}}$ is measured for each cell in ATLAS and $E_{\text{cell}}$ measures the current energy level of the cell.
One thinks of this as the measurement of the energy \textit{over threshold} for the cell.

Topocluster \textit{seeds} are defined as calorimeter cells which have a significance $\calosig > 4 $.
These are the inputs to the algorithm; one iteratively tests all cells adjacent to these seeds for $\calosig > 2$.
Each cells passing this selection is then added to the topocluster, and the procedure is repeated.
When the algorithm reaches the point where there are no additional adjacent cells with $\calosig > 2$, every positive-energy cell adjacent to the current proto-cluster is added.
This collection of cells is summed; the summed object is known as a topocluster.
An example of this procedure for a simulation dijet event is shown in Fig.\ref{fig:topocluster}.
\begin{figure}
\caption{Example of topoclustering on a simulated dijet event.} \label{fig:topocluster}
\subfloat[All cells with $\calosig > 4$.]{\includegraphics[width=.45\linewidth]{topoclustering_sig4.pdf}}
\subfloat[All cells with $\calosig > 2$.]{\includegraphics[width=.45\linewidth]{topoclustering_sig2.pdf}} \\
\subfloat[All clustered cells.]{\includegraphics[width=.9\linewidth]{topoclustering_sig0.pdf}}
\end{figure}

\subsection{Muon Spectrometer Tracks}\label{sec:ms_tracks}

Muon spectrometer tracks are fit using the same algorithms as the ID tracks, but different subdetectors.
The tracks are seeded by hits in the MDTs or CSCs.
After seeding in the MDTs and CSCs, the hits from all subsystems are refit as the final MS track.
These tracks are used as inputs to the muon reconstruction, as we will see below.

\section{Physics Object Reconstruction and Quality Identification}

There are essentially six objects used in ATLAS searches for new physics: electrons, photons, muons, $\tau$-jets, jets, and \met.
The reconstruction of these objects is described here; in this thesis, $\tau$ lepton jets are not treated differently from other hadronic jets.
A very convenient summary plot is shown in Fig.\ref{fig:atlas_interactions}.
\begin{figure}
\caption{The interactions of particles with the ATLAS detector.
Solid lines indicate the particle is interacting with the detector, while dashed lines are shown where the particle does not interact.} \label{fig:atlas_interactions}
\includegraphics[width=.45\linewidth]{atlas_particle_interactions}
\end{figure}
This process produces candidate objects, which are then identified by quality.

One often wishes to understand ``how certain'' we are that a particular object is truly the underlying physics object.
In ATLAS, we often generically consider, in order, \textit{very loose}, \textit{loose}, \textit{medium}, and \textit{tight} objects\footnotemark.
\footnotetext{
These are not all used for all objects, but it's conceptally useful to think of these different categories.
}
These are ordered in terms of decreasing object efficiency, or equivalently, decreasing numbers of fake objects.
We will also describe briefly the classification of objects into these categories.

In this thesis, we present a search for new physics in a zero lepton final state; we will provide additional details about jet and \met reconstruction.
% \subsection{Vertices}

% Vertex reconstruction is an important first step in the reconstruction of ATLAS events\cite{ATL-INDET-PUB-2009-001}.
% If two tracks from charged particles point at the same place inside the detector, we can associate these tracks to that point, which we then call a vertex.
% Generally, we speak of primary vertices associated
% \begin{figure}
% \caption{Depiction of different vertices reconstruct by ATLAS.
% Each ATLAS event has the primary vertex, b-physics vertices, and pileup vertices.} \label{fig:topocluster}
% \includegraphics[width=.45\linewdith]{vertex_reconstruction} \\
% \end{figure}

\subsection{Electrons and Photons}

\subsubsection{Reconstruction}
The reconstruction of electrons and photons (often for brevity called ``electromagnetic objects'') is very similar \cite{Aaboud:2016yuq,PERF-2013-05, PERF-2013-03 }.
This is because the reconstruction begins with the energy deposit in the calorimeter in the form of an electromagnetic shower.
For any incoming $e/\gamma$, this induces many more electrons and photons in the shower; the measurement in the calorimeter is similar for these two objects.

One thus begins the reconstruction of electromagnetic objects from the sliding-window clusters reconstructed from the EM calorimeter, as described in Sec.\ref{sec:id_tracks}.
These $E > 2.5 \GeV$ clusters the the primary seed for electrons and photons.
One then looks for all ID tracks within $\Delta R < 0.3$.\todo{check delta R defined somewhere}
We ``match'' the track and cluster if they are within $\Delta \phi < 0.2$ in the direction of track curvature, or $\Delta \phi < 0.05$ in the direction opposite the track curvature.
Those track-cluster seeds with tracks pointing to the primary vertex are reconstructed as electrons.

For photons, we have two options to consider, known as \textit{converted} and \textit{unconverted} photons.
Due to the high energy of the LHC collisions, typical photons have energy $\order 1 \GeV$; at this scale, photons interact almost exclusively via pair-production in the presence of the detector material \todo{DIAGRAM}.
If the track-cluster seed has a track which does not point at the primary vertex, we reconstruct this object as a converted photon.
This happens since the photon travels a distance before decay into two electrons, and see the tracks coming from this secondary vertex.
Those clusters which do not have any associated tracks are then reconstruced as an unconverted photon.

The final step in electromagnetic object reconstruction is the final energy value assigned to these objects; this process is different between electrons and photons due to their differing signatures in the EM calorimeter.
In the barrel, electrons energies are assigned as the sum of the 3 clusters in $\eta$ and 7 clusters in $\phi$ to account for the electron curving in the $\phi$ direction.
Barrel photons are assigned the energy sum of $(3,5)$ clusters in $(\eta, \phi)$ space.
In the endcap, the effect of the magnetic field on the electrons is smaller, and there is a coarser granularity.
Both objects sum the $(5,5)$ clusters for their final energy value.

\subsubsection{Quality Identification}

Electrons have a number of important backgrounds which can give fakes.
Fake electrons come primarily from secondary vertices in hadron decays or misidentified hadronic jets.
To reduce these backgrounds, quality requirements are imposed on electron candidates.
Loose electrons have requirements imposed on the shower shapes in the electromagnetic calorimeter and on the quality of the associated ID track.
There is also a requirement that there is a small energy deposition in the hadronic calorimeter behind the electron, to avoid jets being misidentified as electrons (low hadronic leakage).
Medium and tight electrons have increasingly stronger requirements on these variables, and additional requirements on the isolation (as measured by $\Delta R$) and matching of the ID track momentum and the calorimeter energy deposit.

Photons are relatively straightforward to measure, since there are few background processes\cite{ATL-PHYS-PUB-2016-015}.
The primary one is pion decays to two photons, which can cause a jet to be misidentified as photon.
Loose photons have requirements on the shower shape and hadronic leakage.
Tight photons have tighter shower shape cuts, especially on the high granularity first layer of the EM calorimeter.
The efficiency for unconverted tight photons as a function of $\pt$ is should in
\begin{figure}
\caption{Unconverted photon efficiency as measured in \cite{ATL-PHYS-PUB-2016-015}.} \label{fig:photon_eff}
\includegraphics[width=.45\linewidth]{photon_efficiency}
\end{figure}

\subsection{Muons}

\subsubsection{Reconstruction}

Muons are reconstructed using measurements from all levels of the ATLAS detector\cite{PERF-2015-10}.
They leave a ID track, a small, characteristic deposition in the EM calorimeter, and then a track in the muon spectrometer.
The primary reconstruction technique produces a so-called \textit{combined} muon.
``Combined'' means using a combination of the ID and MS tracks to produce the final reconstruced muon kinematics.
This is done by refitting the hits associated to both tracks, and using this refit track for the muon kinematics.
This process produces the best measured muons, although several other worse algorithms are used when the full detector information is missing.
An example is in the region $2.5 < |\eta| < 2.7$ outside the ID acceptance; in this region, MS tracks are used without the corresponding ID tracks.

\subsubsection{Quality Identification}

Several additional criteria are used to assure muon measurements are free of significant background contributions, especially from pion and kaon decays to muons.
Muons produced via these decay processes are often characterized by a ``kink''.
Candidate muons with a poor fit quality, characterized by $\chi^2/\text{n.d.f.}$, are thus rejected.
Additionally, the absolute difference in momentum measurements between the ID and MS provide another handle, since the other decay products from hadron decays carry away some amount of the initial hadron momentum.
This is measured by
\begin{equation}
\rho' = \frac{|\pt^{\text{ID}} - \pt^{\text{MS}} |}{\pt^{\text{Combined}}}.
\end{equation}
Additionally, there is a requirement on the $q/p$ significance, defined as
\begin{equation}\label{eq:muon_sig}
S_{q/p} = \frac{|(q/p)^{\text{ID}} - (q/p)^{\text{MS}} |}{\sqrt{\sigma_{\text{ID}}^2 + \sigma_{\text{MS}}^2  }}.
\end{equation}
The $\sigma_{\text{ID,MS}}$ in the denominator of Eq.\ref{eq:muon_sig} are the uncertainties on the corresponding quantity from the numerator.
Finally, cuts are placed on the number of hits in the various detector elements.

Subsequently tighter cuts on these variables allow one to define the different muon identification criteria.
Loose muons have the highest reconstruction efficiency, but the highest number of fake muons, since there are no requirements on the number of subdetector hits and the loosest requirements on the suite of quality variables.
Medium muons consist of Loose muons with tighter cuts on the quality variables; they also require more than three MDT hits in at least two MDT layers.
These are the default used by ATLAS analyses.
Tight muons have stronger cuts than those of the medium selection, and reducing the reconstruction efficiency.
The reconstruction efficiency as a function of \pt can be seen for Medium muons in Fig.\ref{fig:muon_eff}.

\begin{figure}
\caption{Medium muon efficiency as measured in \cite{PERF-2015-10}.} \label{fig:muon_eff}
\includegraphics[width=.45\linewidth]{muon_efficiency}
\end{figure}

\subsection{Jets}
\todo{cite paper/note}

Jets are composite objects corresponding to many physical particles.
This is a striking difference from the earlier particles.
Fortunately, we normally (and in this thesis) care about the original particle produced in primary collision.
In the SM, this corresponds to quarks and gluons; due to the hadronization process described in \ref{ch:sm}, free quarks and gluons spontaneously hadronize and produce a hadronic shower, which we call a jet.
These showers can be measured by the EM and hadronic calorimeters, and the charged portions can be measured in the ID.
The first question is how to combine these measurements into a composite object representing the underlying physical parton.
This is done via jet algorithms.

\subsection{Jet Algorithms}

It might seem straightforward to combine the underlying physical particles into a jet.
There are three important characteristics required for any jet reconstruction algorithm to be used by ATLAS.
\begin{itemize}
\item Collinear safety - if any particle with four-vector $p$ is replaced by two particles of $p_1, p_2$ with $p = p_1 + p_2$, the subsequent jet should not change
\item Radiative (infrared) safety - if any particle with four-vector $p$ radiates a particle of energy $\alpha \rightarrow 0$, the subsequent jet should not change
\item Fast - the jet algorithm should be ``fast enough'' to be useable by ATLAS computing resources
\end{itemize}
The first two requirements can be seen in terms of requirements on soft gluon emission.
Since partons emit arbitrarily soft gluons freely, one should expect the algorithms to not be affected by this emission.
The final requirement is of course a practical limitation.

The algorithms in use by ATLAS (and CMS) which satisfies these requirements are collectively known as the \kt algorithms \cite{Ellis:1993tq,Cacciari:2005hq,Cacciari:2008gp}.
These algorithms iteratively combine the ``closest'' objects, defined using the following distance measures :
\begin{equation}
\begin{aligned}\label{eq:kt}
d_{ij} &= \text{min}(k_{T,i}^{2p} , k_{T,j}^{2p} )  \frac{\Delta_{ij}^2 }{R^2} \\
d_{iB} &= k_{T_i}^{2p}
\end{aligned}
\end{equation}
In Eq.\ref{eq:kt}, $k_T,i$ is the transverse momentum of $i$-th jet \textit{constituent}, $\Delta_{ij}$ is the angular distance between the constituents.
Both $R$ and $p$ are adjustable parameters; $R$ is known as the (jet) \textit{cone size} and $p$ regulates the power of the energy vs the geometrical scales.
The algorithm sequence, for a given set of objects $i$ with four-vector $k$ :
\begin{enumerate}
\item Find the minimum distance in the set of all $d_{ij}$ and $d_{iB}$.
\item If the distance is one of the $d_{ij}$, combine the input pair of object $i,j$ and return to (1).
If the distance is one of the $d_{iB}$, remove the object from the list, call it a jet, and return to (1).
\end{enumerate}
This process ends when all objects $i$ have been added to a jet.

Any choice of $(p,R)$ has the requirements of collinear and radiative safety.
In essence, the choice is then to optimize based on speed and the potential for new physics discoveries.
In ATLAS, we make the choice of $p = -1$; this is also known as the \textit{anti-}\kt algorithm.
The choice of $R = 0.4$ is used for the distance parameter of the jets.

The primary ``nice'' quality of this algorithm can be seen with the following example.
Consider three inputs to an anti-\kt algorithm, all with $\eta = 0$ :
\begin{itemize}
\item Object 1 : (\pt, $\phi$) = (30 \GeV, 0)
\item Object 2 : (\pt, $\phi$) = (20 \GeV, -0.2)
\item Object 3 : (\pt, $\phi$) = (10 \GeV, 0.2)
\item Object 4 : (\pt, $\phi$) = (1  \GeV, 0.5)
\end{itemize}.
In the case shown, it seems natural to first combine the ``bigger'' objects 1 and 2.
These then pick up the extra small object 3, and object 4 is not included in the jet.
This is exactly what is done by the anti-\kt algorithm.
The (normal) \kt algorithm with $p = 1$ instead combines the smallest objects, 3 and 4, first.
Object 1 and 2 combine to form their own jet, instead of these jets picking up object 3.
This behavior is not ideal due to the effects of pileup.

In ATLAS, jets are reconstructed using the  calorimeter topoclusters using the anti-\kt algorithm with $R = 0.4$.
The collection of all topoclusters reconstructed as in Sec.\ref{sec:topoclusters}, and used as the general object

\subsection{Jet Reconstruction and Calibration}

Jets are reconstructed from the

\subsection{Jet Calibration}

\subsection{B-jets}




\subsection{Missing Transverse Momentum}
\todo{cite paper/notes}

\section{Maybe PFlow?}